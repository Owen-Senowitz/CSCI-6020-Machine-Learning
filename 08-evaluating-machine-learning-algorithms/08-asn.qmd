---
title: "Written Assignment 08"
author: "Owen Senowitz"
date: today
date-format: long
number-sections: true
number-depth: 3
fig-cap-location: margin
format:
  html:
    toc: true
    toc-location: right
    number-sections: true
    number-depth: 3
    html-math-method: katex
    embed-resources: true
    self-contained: true
# bibliography: dasc-6000.bib 
# csl: ieee-with-url.csl
# linkcolor: red
# urlcolor: blue
# link-citations: yes
# header-includes:
#   - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# Assignment Goal {.unnumbered}

The overarching goal for this assignment is to assess your understanding of evaluating machine learning models. 

# Instructions {.unnumbered}

Please show all your work. Simply providing the final answer is treated as no response. If you do not use R or Python notebooks, it is fine. However, the document structure should be preserved if you choose to use Microsoft Word or something else.

Please submit your response either as a self-contained HTML or PDF document.

There are two questions. Each question carries 50 points.

# Basic Evaluation Measures - Categorical Target

The table below shows the predictions made for a **categorical target feature** by a model for a test dataset.

```{r}
#| echo: false
library(readr)
df1 <- readr::read_csv("./categorical-target.csv", col_names = TRUE)
```


```{r}
#| echo: false
#| tbl-cap-location: margin
knitr::kable(df1, caption = 'Predictions made for a categorical target feature.', align = "lrr")
```


Based on this test set, calculate the following evaluation measures.

(a) A confusion matrix and the misclassification rate

    Confusion matrix

    True Negatives (TN): Target = False, Prediction = False

    Rows: 1, 2, 3, 4, 6, 9, 10, 11, 13, 15, 16 (Count = 11)

    False Positives (FP): Target = False, Prediction = True

    Rows: None (Count = 0)

    False Negatives (FN): Target = True, Prediction = False

    Rows: 17 (Count = 1)

    True Positives (TP): Target = True, Prediction = True

    Rows: 5, 7, 8, 12, 14, 18, 19, 20 (Count = 8)

    $\text{Confusion Matrix} =
\begin{bmatrix}
11 & 0 \\
1 & 8
\end{bmatrix}$

    $\text{Misclassification Rate} = \frac{\text{FP} + \text{FN}}{\text{Total Samples}}$

    $\text{FP} = 0, \quad \text{FN} = 1, \quad \text{Total Samples} = 20$

    $\text{Misclassification Rate} = \frac{0 + 1}{20} = \frac{1}{20} = 0.05$
    
(a) The average class accuracy (harmonic mean)

    $\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} = \frac{8}{8 + 0} = 1.0$

    $\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} = \frac{8}{8 + 1} = 0.8889$

    $\text{Harmonic Mean} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2 \times 1.0 \times 0.8889}{1.0 + 0.8889} = \frac{1.7778}{1.8889} = 0.9412$

(a) The precision, recall, and $F_1$ measure

    $F_1 = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2 \times 1.0 \times 0.8889}{1.0 + 0.8889} = \frac{1.7778}{1.8889} = 0.9412$



# Basic Evaluation Measures - Continuous Target

The table below shows the predictions made for a **continuous target feature** by two different prediction models for a test dataset.

```{r}
#| echo: false
library(readr)
df2 <- readr::read_csv("./continuous-target.csv", col_names = TRUE)
```


```{r}
#| echo: false
#| tbl-cap-location: margin
knitr::kable(df2, caption = 'Predictions made for a continuous target feature.', align = "lrrr")
```

(a) Based on these predictions, calculate the evaluation measures listed below for each
model.

    i. The sum of squared errors
    
    $\text{SSE} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$

    $\text{SSE}_{\text{Model 1}} = 33500$

    $\text{SSE}_{\text{Model 2}} = 94738$
    
    ii. The $R^2$ measure

    $R^2 = 1 - \frac{\text{SSE}}{\text{SST}}$

    $\bar{y} = \frac{\sum_{i=1}^{n} y_i}{n} = \frac{75457}{30} \approx 2515.23$

    $\text{SST} = \sum_{i=1}^{n} (y_i - \bar{y})^2 = 467334$

    $R^2_{\text{Model 1}} = 1 - \frac{33500}{467334} \approx 0.9284$

    $R^2_{\text{Model 2}} = 1 - \frac{94738}{467334} \approx 0.7976$

(a) Based on the evaluation measures calculated, which model do you think is performing better for this dataset?

    For SSE Model 1 had a much lower SSE, meaning its predictions are closer to the target values on average. For $R^2$ Model 1 explains more variance in the target values compared to Model 2. Model 1 performs better than Model 2 because it had a lower SSE and a higher $R^2$.

