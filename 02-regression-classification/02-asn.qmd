---
title: "Written Assignment 02"
author: "Owen Senowitz"
date: today
number-sections: true
number-depth: 3
format:
  html:
    toc: true
    toc-location: right
    number-sections: true
    number-depth: 3
    html-math-method: katex
    embed-resources: true
# bibliography: dasc-6000.bib 
# csl: ieee-with-url.csl
# linkcolor: red
# urlcolor: blue
# link-citations: yes
# header-includes:
#   - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# Assignment Goal {.unnumbered}

The goal of this assignment is to demonstrate your understanding of fundamentals of machine learning -- trade-off between prediction accuracy and model interpretability, supervised versus unsupervised learning, and regression versus classification problems. 

# Question: Simple Regression Models

Consider the following figure:

![](models.png)


Shown in the leftmost subfigure is the scatter plot of dataset. \emph{Age} is the predictor variable and \emph{Income} is the response/target variable. The next three subfigures are simple regression models which are referred to as $M_1$, $M_2$, and $M_3$. One of the models is an overfit, another is just right, and the remaining one is underfit. Which model is an overfit model? Underfit model? Just about right model? What is the basis for your answers?


**Answer:**

$M_1$ Under Fit Model: Model $M_1$ looks like the underfit model. It's too simple and doesn't capture the pattern in the data very well. It probably won't do well on either this data or new data.

$M_2$ Overfit Model: I think model $M_3$ is the overfit one because it seems like it's trying too hard to match every single point in the data. It might do really well on this dataset, but it'll probably mess up on new data. 

$M_3$ Just Right Model: Model $M_2$ seems just right. It captures the pattern in the data without being too complicated. It should work well on both this data and new data.




# Question: Consistent Prediction Models

Consider the training data shown below, in which **ID**, **Occupation**, **Age**, and **Loan-Salary Ratio** are the predictor variables, and **Outcome** is the response/target variable.


```{r}
#| echo: false
ID <- c(1,2,3,4,5,6,7,8,9,10)
Occupation <- c("industrial", "professional", "professional", "professional", "industrial ", "industrial", "professional", "professional", "industrial", "industrial")
Age <- c(34, 41, 36, 41, 48, 61, 37, 40, 33, 32)
Loan_Salary_Ratio <- c(2.96, 4.64, 3.22, 3.11, 3.80, 2.52, 1.50, 1.93, 5.25, 4.15)
Outcome <- c("repaid", "default", "default", "default", "default", "repaid", "repaid", "repaid", "default", "default")
df <- data.frame(ID, Occupation, Age, Loan_Salary_Ratio, Outcome)
# print(df)
```

<!--

# replace _ in column names by a space
knitr::kable(iris2, col.names = gsub("[_]", " ", names(iris)))

knitr::kable(iris, col.names = c('We', 'Need', 'Five', 'Names', 'Here'))
-->


```{r}
#| echo: false
#| tbl-cap-location: margin
knitr::kable(df, caption = 'A machine learning application dataset.', col.names = gsub("[_]", " ", names(df)), align = "rlccl")
```


Next consider the following prediction model (called $M_1$), which is developed using the data in the table above:

```
if Loan-Salary Ratio > 3 then
    Outcome=’default’
else
    Outcome=’repay’
end if
```

Why is this model a consistent prediction model? Explain. This model also uses two principles: feature design and feature selection. Explain these two principles.

**Answer:**

**Q1) Why is this model a consistent prediction model?**

The model is consistent because it correctly predicts the "Outcome" for all the examples in the training data. Here’s how it works. The model says that if the Loan-Salary Ratio is greater than 3, the outcome should be "default." If the Loan-Salary Ratio is 3 or less, the outcome should be "repaid."

Now, if you look at the data. For all the entries where the Loan-Salary Ratio is greater than 3, the actual outcome is "default." For all the entries where the Loan-Salary Ratio is 3 or less, the actual outcome is "repaid."

**Q2) This model also uses two principles: feature design and feature selection.**

This is about creating or choosing the right features (variables) that will help the model make accurate predictions. In this case, the model is designed around the "Loan-Salary Ratio" as the main feature. It assumes that this ratio is a strong indicator of whether someone will repay or default on a loan. This is about picking the most important features out of all the available ones. Here, the model is only using the "Loan-Salary Ratio" and ignoring other features like Occupation and Age. The idea is that the Loan-Salary Ratio is the most useful feature for making the prediction.


# Question: Consistent Prediction Model

Consider the training data shown in the following table. ID, Amount, Salary, Ratio, Age, Occupation, House, and Type are predictor variables, and Outcome is the response/target variable.


```{r}
#| echo: false
# install readr, if not already installed
# install.packages("readr")
# load readr
library(readr)
df <- readr::read_tsv("./data.tsv", col_names = FALSE)
column_names <- c("ID", "Amount", "Salary", "Loan-Salary Ratio", "Age", "Occupation", "House", "Type", "Outcome")
colnames(df) <- column_names
print(df)
```

```{r}
#| echo: false
#| tbl-cap-location: margin
knitr::kable(df, caption = 'Another machine learning application dataset.', col.names = gsub("[_]", " ", names(df)), align = "lrrcrrrrr")
```

Next consider the following prediction model (called $M_2$) which is developed using the data in the table above:

```
if Loan-Salary Ratio < 1.5 then
    Outcome=’repay’
else if Loan-Salary Ratio > 4 then
    Outcome=’default’
else if Age < 40 and Occupation =’industrial’ then
    Outcome=’default’
else
    Outcome=’repay’
end if
```

Is this model a consistent prediction model? Explain. Which model is better? $M_1$ or $M_2$. Why?

**Answer:**

Model $M_1$ is very simple it only uses the Loan-Salary Ratio to decide if someone will "default" or repay. It worked perfectly with the first dataset because it only had one clear rule: if the ratio is above 3, "default" otherwise, repay.

Model $M_2$ is more complex. It uses not just the Loan-Salary Ratio, but also Age and Occupation to make predictions. Because of this, it can handle more varied data, like the second dataset, where there are more factors to consider.

So, Model $M_2$ is better for this dataset because it can correctly predict the outcomes even when other factors (like Age and Occupation) are involved. It’s more flexible and can handle more complex situations than Model $M_1$.


# Question: Classification or Regression?

Explain whether each scenario is a classification or regression problem.

## Scenario 1

We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.

**Answer:**

In this scenario, the goal is to understand which factors affect CEO salary. Since salary is a numerical value, and you’re trying to predict it based on other factors (profit, number of employees, industry), this is a regression problem. Regression is used when the target variable is continuous and numerical, like predicting a salary.

## Scenario 2 

We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.

**Answer:**

In this scenario, the goal is to predict whether a new product will be a success or a failure based on data from similar products. Since the outcome (success or failure) is a categorical variable, this is a classification problem. Classification is used when the target variable is categorical, like determining whether something will be a success or failure.